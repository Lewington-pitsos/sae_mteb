{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 1922.2274954319,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.85",
  "scores": {
    "test": [
      {
        "accuracy": 0.8262653898768809,
        "f1": 0.8144650670105529,
        "f1_weighted": 0.8277299059951891,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8262653898768809,
        "scores_per_experiment": [
          {
            "accuracy": 0.8196534427724578,
            "f1": 0.8087822273751375,
            "f1_weighted": 0.8192425247098241
          },
          {
            "accuracy": 0.8488372093023255,
            "f1": 0.8362465343511427,
            "f1_weighted": 0.8506922385806946
          },
          {
            "accuracy": 0.8331053351573188,
            "f1": 0.8187881830079612,
            "f1_weighted": 0.8349358792469374
          },
          {
            "accuracy": 0.8248974008207934,
            "f1": 0.8134653423478233,
            "f1_weighted": 0.8296678575349853
          },
          {
            "accuracy": 0.8527131782945736,
            "f1": 0.8413667535248123,
            "f1_weighted": 0.8535166587486456
          },
          {
            "accuracy": 0.8540811673506612,
            "f1": 0.8439967432206902,
            "f1_weighted": 0.8558071621148801
          },
          {
            "accuracy": 0.7975376196990424,
            "f1": 0.7877304657547303,
            "f1_weighted": 0.7961604609432058
          },
          {
            "accuracy": 0.801641586867305,
            "f1": 0.7874997202344652,
            "f1_weighted": 0.8030382410910838
          },
          {
            "accuracy": 0.8036935704514364,
            "f1": 0.7952835015505346,
            "f1_weighted": 0.8065359467989058
          },
          {
            "accuracy": 0.8264933880528956,
            "f1": 0.811491198738231,
            "f1_weighted": 0.8277020901827291
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.8141387024608502,
        "f1": 0.8063963023950184,
        "f1_weighted": 0.8154344374387325,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8141387024608502,
        "scores_per_experiment": [
          {
            "accuracy": 0.8013422818791947,
            "f1": 0.7919509978804616,
            "f1_weighted": 0.8001523042626109
          },
          {
            "accuracy": 0.8402684563758389,
            "f1": 0.8338504833173772,
            "f1_weighted": 0.842618786574828
          },
          {
            "accuracy": 0.8223713646532439,
            "f1": 0.8126548229111014,
            "f1_weighted": 0.8239571305890603
          },
          {
            "accuracy": 0.8174496644295302,
            "f1": 0.8131982126007213,
            "f1_weighted": 0.82185862415765
          },
          {
            "accuracy": 0.8402684563758389,
            "f1": 0.8322501520792922,
            "f1_weighted": 0.8402774106815756
          },
          {
            "accuracy": 0.8447427293064877,
            "f1": 0.839909267977417,
            "f1_weighted": 0.8460273811739624
          },
          {
            "accuracy": 0.778076062639821,
            "f1": 0.7685900299989812,
            "f1_weighted": 0.777787021306574
          },
          {
            "accuracy": 0.7838926174496644,
            "f1": 0.7749294207364219,
            "f1_weighted": 0.7859007303107769
          },
          {
            "accuracy": 0.7986577181208053,
            "f1": 0.7942501652881795,
            "f1_weighted": 0.8007282202274005
          },
          {
            "accuracy": 0.814317673378076,
            "f1": 0.802379471160231,
            "f1_weighted": 0.8150367651028876
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}