{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 308.5485725402832,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.85",
  "scores": {
    "test": [
      {
        "accuracy": 0.7894892840857273,
        "f1": 0.786935634661938,
        "f1_weighted": 0.7913656764292156,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7894892840857273,
        "scores_per_experiment": [
          {
            "accuracy": 0.7528499772001824,
            "f1": 0.7522433497865401,
            "f1_weighted": 0.7527226784613009
          },
          {
            "accuracy": 0.7783857729138167,
            "f1": 0.7791573010663114,
            "f1_weighted": 0.7877904210963026
          },
          {
            "accuracy": 0.7966256269949841,
            "f1": 0.7916106344617415,
            "f1_weighted": 0.798909187678135
          },
          {
            "accuracy": 0.8057455540355677,
            "f1": 0.8001877182159856,
            "f1_weighted": 0.8074083952995842
          },
          {
            "accuracy": 0.8178294573643411,
            "f1": 0.8162249871341314,
            "f1_weighted": 0.8189763431964326
          },
          {
            "accuracy": 0.7767897856817145,
            "f1": 0.7731052482786986,
            "f1_weighted": 0.7761347128245891
          },
          {
            "accuracy": 0.7615139078887369,
            "f1": 0.761351921419338,
            "f1_weighted": 0.761700059795152
          },
          {
            "accuracy": 0.8166894664842681,
            "f1": 0.8124075869136068,
            "f1_weighted": 0.8191211928893206
          },
          {
            "accuracy": 0.7831737346101231,
            "f1": 0.7860390248291057,
            "f1_weighted": 0.7843304716597458
          },
          {
            "accuracy": 0.8052895576835385,
            "f1": 0.797028574513922,
            "f1_weighted": 0.8065633013915936
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7815212527964206,
        "f1": 0.7840785629829179,
        "f1_weighted": 0.7823913643806664,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7815212527964206,
        "scores_per_experiment": [
          {
            "accuracy": 0.7225950782997763,
            "f1": 0.7293868812268848,
            "f1_weighted": 0.7224581966922531
          },
          {
            "accuracy": 0.7789709172259508,
            "f1": 0.7833138708806476,
            "f1_weighted": 0.7836175316578237
          },
          {
            "accuracy": 0.7906040268456376,
            "f1": 0.7895401006362409,
            "f1_weighted": 0.7917539896094725
          },
          {
            "accuracy": 0.7950782997762863,
            "f1": 0.7979318081372145,
            "f1_weighted": 0.7971377262057557
          },
          {
            "accuracy": 0.8165548098434005,
            "f1": 0.8207719618889754,
            "f1_weighted": 0.8163338872112021
          },
          {
            "accuracy": 0.7651006711409396,
            "f1": 0.7663834022675836,
            "f1_weighted": 0.7633821416168457
          },
          {
            "accuracy": 0.7472035794183445,
            "f1": 0.7528167386987241,
            "f1_weighted": 0.7473623671969535
          },
          {
            "accuracy": 0.8120805369127517,
            "f1": 0.8112575228983395,
            "f1_weighted": 0.8135062133038767
          },
          {
            "accuracy": 0.7843400447427293,
            "f1": 0.7894854225825384,
            "f1_weighted": 0.7844258404565067
          },
          {
            "accuracy": 0.8026845637583893,
            "f1": 0.7998979206120297,
            "f1_weighted": 0.8039357498559735
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}